{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a74ae099",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc04748",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.classify import NaiveBayesClassifier, accuracy\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
    "\n",
    "import spacy\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.feature_extraction import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fe9cf0",
   "metadata": {},
   "source": [
    "# Setting Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee7408a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "eng_stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e80e2f1",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd70fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"./Dataset/imdb-movies-dataset.csv\")\n",
    "\n",
    "dataset.isnull().sum()\n",
    "dataset = dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d2f569c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Idea of You</td>\n",
       "      <td>6.4</td>\n",
       "      <td>This film, as well as the reaction to it, is a...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kingdom of the Planet of the Apes</td>\n",
       "      <td>7.3</td>\n",
       "      <td>I'm a big fan of all the planet of the apes, a...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Unfrosted</td>\n",
       "      <td>5.5</td>\n",
       "      <td>Pretty much the worst criticism you can lay on...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Fall Guy</td>\n",
       "      <td>7.3</td>\n",
       "      <td>Just got out of the Austin premier at SXSW and...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Challengers</td>\n",
       "      <td>7.7</td>\n",
       "      <td>This is a tough one. I liked the concept and t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Title  ...  Sentiment\n",
       "0                    The Idea of You  ...   positive\n",
       "1  Kingdom of the Planet of the Apes  ...   positive\n",
       "2                          Unfrosted  ...   positive\n",
       "3                       The Fall Guy  ...   positive\n",
       "4                        Challengers  ...   positive\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Sentiment'] = dataset['Rating'].apply(lambda x: 'positive' if x > 5 else 'negative') \n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe6bb49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "positive    4514\n",
       "negative     272\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce01de8d",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56335e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(sentence):\n",
    "    \n",
    "    # Tokenize\n",
    "    word_list = word_tokenize(sentence)\n",
    "    word_list = [word.lower() for word in word_list] # lower biar aman\n",
    "    \n",
    "    # Stopwords\n",
    "    no_stopwords = [token for token in word_list if token not in eng_stopwords]\n",
    "    \n",
    "    # Remove Punctuation\n",
    "    no_punc = [token for token in no_stopwords if token.isalpha()] \n",
    "    \n",
    "    # Stemming\n",
    "    stemmed = [stemmer.stem(token) for token in no_punc]\n",
    "    \n",
    "    # Lemmatizing\n",
    "    lemmatized = [lemmatizer.lemmatize(token) for token in stemmed] # langsung pake default, kalo mau lebih bagus bikin function get_tag kaya pas quiz sebelumnya\n",
    "    \n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01eb2672",
   "metadata": {},
   "source": [
    "# Frequency Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "550907fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('film', 13735), ('movi', 13267), ('one', 6096), ('like', 5519), ('charact', 4285), ('time', 3934), ('make', 3703), ('see', 3621), ('stori', 3543), ('good', 3259)]\n"
     ]
    }
   ],
   "source": [
    "# Frequency Distribution\n",
    "X = dataset[\"Review\"]\n",
    "Y = dataset[\"Sentiment\"]\n",
    "\n",
    "all_reviews = ' '.join(X)\n",
    "all_tokens = preprocess_text(all_reviews)\n",
    "\n",
    "freq_dist = FreqDist(all_tokens)\n",
    "\n",
    "print(freq_dist.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6b1375",
   "metadata": {},
   "source": [
    "# Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53c8129c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Text Features\n",
    "def extract_feature(review):\n",
    "    features = {} # simpan dalam bentuk dictionary\n",
    "    for word in freq_dist.keys():\n",
    "        features[word] = (word in review)\n",
    "    \n",
    "    return features\n",
    "\n",
    "feature_sets = [(extract_feature(preprocess_text(review)), sentiment) for (review, sentiment) in zip(X,Y)]\n",
    "\n",
    "# Opsional kalo disuruh aja\n",
    "from random import shuffle\n",
    "shuffle(feature_sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912c8425",
   "metadata": {},
   "source": [
    "# Load and Train Model : Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd715c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load & Train Model\n",
    "def train_and_save_model():\n",
    "    train_count = int(len(feature_sets) * 0.8) # Sesuain ama ketentuan soal ya dimintanya berapa persentase testing / training nya\n",
    "    train_set = feature_sets[:train_count]\n",
    "    test_set = feature_sets[train_count:]\n",
    "\n",
    "    classifier = NaiveBayesClassifier.train(train_set)\n",
    "    test_accuracy = accuracy(classifier, test_set)\n",
    "    print(f\"Akurasi data test: {test_accuracy * 100:.2f}%\")\n",
    "    classifier.show_most_informative_features(5)\n",
    "\n",
    "    # Buat read / write file juga bebas mau pake cara ini atau pake yg syntax with open (\"file_name\", \"action\") as file:\n",
    "    file = open(\"model.pickle\", \"wb\") # Kalo pake cara ini jangan lupa file.close()\n",
    "    pickle.dump(classifier, file)\n",
    "    file.close()\n",
    "\n",
    "    return classifier\n",
    "        \n",
    "def load_model():\n",
    "    if os.path.exists(\"./model.pickle\"): # Validasi kaya gini bebas mau pake os atau pake try except\n",
    "        file = open(\"model.pickle\", \"rb\") \n",
    "        classifier = pickle.load(file)\n",
    "        print(\"Model loaded successfully.\")\n",
    "        file.close()\n",
    "    else:\n",
    "        print(\"Model not found! Training model...\")\n",
    "        classifier = train_and_save_model()\n",
    "    return classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59321892",
   "metadata": {},
   "source": [
    "# Word Embedding Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd0734ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF\n",
    "def tf_idf(query):\n",
    "    vectorizer = TfidfVectorizer(stop_words= 'english')\n",
    "    tfidf_matrix = vectorizer.fit_transform(dataset[\"Review\"]) \n",
    "    # hitung .fit_transform buat hitung frekuensi kemunculan kata + ubah jadi vektor\n",
    "\n",
    "    query_vec = vectorizer.transform([query]) # ubah query / inputted sentence jadi vektor. Pake [] karena nerimanya dalam bentuk list\n",
    "\n",
    "    similarity = cosine_similarity(query_vec, tfidf_matrix).flatten() # Ubah hasil jadi 1 Dimensi \n",
    "    dataset['Similarity'] = similarity # Tambahin kolom baru di dataframe kita dengan judul \"Similarity\"\n",
    "\n",
    "    dataset_sorted = dataset.sort_values(by='Similarity', ascending= False) # Sort dari hasil nilai Similarity Besar -> Kecil\n",
    "    \n",
    "    print(\"\\nTop 2 Movie Recommendation for you:\")\n",
    "    print(\"1: \", dataset_sorted.iloc[0,0]) \n",
    "    print(\"2: \", dataset_sorted.iloc[1,0])\n",
    "     # iloc = \"integer location\". Digunain untuk ambil data per row, col. Jadi iloc[0,0] ambil baris pertama dari data dan kolom 0 yang berupa titlenya. Kalau mau ambil semua data dalam 1 row berarti iloc[0] aja\n",
    "    \n",
    "# Ngram-Models (Unigram, Bigram, Trigram)\n",
    "def ngram(query):\n",
    "    ngram_n = 3 \n",
    "    ngram_range = (1, ngram_n)\n",
    "\n",
    "    vectorizer = TfidfVectorizer(ngram_range= ngram_range, stop_words='english') # bekerja dari unigram - trigram\n",
    "    tfidf_matrix = vectorizer.fit_transform(dataset[\"Review\"])\n",
    "\n",
    "    query_vec = vectorizer.transform([query])\n",
    "\n",
    "    similarity = cosine_similarity(query_vec, tfidf_matrix).flatten()\n",
    "    dataset['Similarity'] = similarity\n",
    "\n",
    "    dataset_sorted = dataset.sort_values(by='Similarity', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 2 Movie Recommendation for you:\")\n",
    "    print(\"1: \", dataset_sorted.iloc[0,0])\n",
    "    print(\"2: \", dataset_sorted.iloc[1,0])\n",
    "    \n",
    "# Word2Vec\n",
    "# Word2Vec: Menghasilkan vektor level kata. Diperlukan fungsi tambahan (seperti avg_vector) untuk hasilin vector query / sentence supaya bisa dibandingin pake consine_similarity\n",
    "def avg_vector(tokens, model): # Intinya function buat hasilin vektor rata\" dari sebuah query / sentence input\n",
    "    vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "    if not vectors:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(vectors, axis= 0)  \n",
    "\n",
    "def word2vec(query):\n",
    "    tokenized_docs = [preprocess_text(token) for token in dataset[\"Review\"]]\n",
    "    w2v_model = Word2Vec(sentences=tokenized_docs, vector_size=100, window=5, min_count=1, sg = 1) # ini pake skip-gram kalo sg = 1, sg = 0 pake CBOW\n",
    "\n",
    "    query_vec = avg_vector(preprocess_text(query), w2v_model).reshape(1, -1) # Di reshape untuk ikutin ketentuan ketika digunakan di cosine_similarity\n",
    "\n",
    "    review_vec = [avg_vector(preprocess_text(token), w2v_model) for token in dataset[\"Review\"]]\n",
    "    similarity = cosine_similarity(query_vec, review_vec)[0]\n",
    "\n",
    "    dataset['Similarity'] = similarity\n",
    "\n",
    "    dataset_sorted = dataset.sort_values(by='Similarity', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 2 Movie Recommendation for you:\")\n",
    "    print(\"1: \", dataset_sorted.iloc[0,0])\n",
    "    print(\"2: \", dataset_sorted.iloc[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b327d3",
   "metadata": {},
   "source": [
    "# NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8c2fb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NER with Spacy\n",
    "paragraph = ' '.join(dataset['Review'].head(500))\n",
    "\n",
    "# spacy.cli.download('en_core_web_sm')\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "# nlp.max_length = 10000000   \n",
    "doc = nlp(paragraph)\n",
    "\n",
    "categories = {}\n",
    "for ent in doc.ents:\n",
    "    label = ent.label_\n",
    "    if label not in categories:\n",
    "        categories[label] = []\n",
    "    categories[label].append(ent.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bf73d7",
   "metadata": {},
   "source": [
    "# Menu Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5513e8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_review = \"No Review\"\n",
    "my_category = \"Unknown\"\n",
    "\n",
    "def menu_1(loaded_classifier):\n",
    "\n",
    "    global my_review, my_category\n",
    "\n",
    "    query = input(\"My query: \")\n",
    "    word_list = word_tokenize(query)\n",
    "    \n",
    "    if len(word_list) > 20: # Depend on the question\n",
    "        my_review = query\n",
    "        query_processed = preprocess_text(query)\n",
    "        input_feature = extract_feature(query_processed)\n",
    "        my_category = loaded_classifier.classify(input_feature)\n",
    "        print(\"Review successfully updated!\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Input must be more than 20 words. Your input has {len(word_list)} words.\")\n",
    "\n",
    "def menu_2(): \n",
    "\n",
    "    if my_review == \"No Review\":\n",
    "        print(\"Please Input Review First\")\n",
    "\n",
    "    else:\n",
    "        print(\"\\nChoose Language Model\")\n",
    "        print(\"1. Word2Vec \\n2. TF-IDF \\n3. N-GRAM\")\n",
    "        x = input(\"Chosen model: \")\n",
    "        \n",
    "        if x == '1':\n",
    "            ngram(my_review)\n",
    "        elif x == '2':\n",
    "            tf_idf(my_review)\n",
    "        elif x == '3':\n",
    "            word2vec(my_review)\n",
    "        else:\n",
    "            print(\"Invalid input\")\n",
    "\n",
    "def menu_3():\n",
    "\n",
    "    print(\"\\nNamed Entity Recognition\")\n",
    "    for label, ent in categories.items():\n",
    "        print(f'{label}: {\", \".join(ent)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec19298",
   "metadata": {},
   "source": [
    "# Main Menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca9f746b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_menu():\n",
    "    loaded_classifier = load_model()\n",
    "\n",
    "    while True:    \n",
    "        print(\"\\nMovie Recommendation Application Based On Reviews\")        \n",
    "        print(f\"Your Review: {my_review}\")\n",
    "        print(f\"Your Category: {my_category}\")\n",
    "        \n",
    "        print('1. Write your review')\n",
    "        print('2. View movie recommendation')\n",
    "        print('3. View NER')\n",
    "        print('4. Exit')\n",
    "        \n",
    "        try: \n",
    "            choice = input(\">> \")\n",
    "            if choice == '1':\n",
    "                menu_1(loaded_classifier)\n",
    "            elif choice == '2':\n",
    "                menu_2()\n",
    "            elif choice == '3':\n",
    "                menu_3()\n",
    "            elif choice == '4':\n",
    "                print(\"Exiting application...\")\n",
    "                break\n",
    "            else:\n",
    "                print(\"Invalid input. Please enter a number between 1 and 4.\")\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter a valid number.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c8c26e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n",
      "\n",
      "Movie Recommendation Application Based On Reviews\n",
      "Your Review: No Review\n",
      "Your Category: Unknown\n",
      "1. Write your review\n",
      "2. View movie recommendation\n",
      "3. View NER\n",
      "4. Exit\n",
      "Invalid input. Please enter a number between 1 and 4.\n",
      "\n",
      "Movie Recommendation Application Based On Reviews\n",
      "Your Review: No Review\n",
      "Your Category: Unknown\n",
      "1. Write your review\n",
      "2. View movie recommendation\n",
      "3. View NER\n",
      "4. Exit\n",
      "Invalid input. Please enter a number between 1 and 4.\n",
      "\n",
      "Movie Recommendation Application Based On Reviews\n",
      "Your Review: No Review\n",
      "Your Category: Unknown\n",
      "1. Write your review\n",
      "2. View movie recommendation\n",
      "3. View NER\n",
      "4. Exit\n",
      "Invalid input. Please enter a number between 1 and 4.\n",
      "\n",
      "Movie Recommendation Application Based On Reviews\n",
      "Your Review: No Review\n",
      "Your Category: Unknown\n",
      "1. Write your review\n",
      "2. View movie recommendation\n",
      "3. View NER\n",
      "4. Exit\n",
      "Exiting application...\n"
     ]
    }
   ],
   "source": [
    "main_menu()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
